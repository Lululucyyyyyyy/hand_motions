{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from cnn_utils import *\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#directions = ['up', 'down', 'left', 'right', 'zoom_in', 'zoom_out', 'two', 'three', 'four', 'five']\n",
    "my_list = []\n",
    "path = \"dataset/*.JPG\"\n",
    "temp = glob.glob(path)\n",
    "for image in temp:\n",
    "    with open(image, 'rb') as file:\n",
    "        img = Image.open(file)\n",
    "        img = img.resize((224, 224))\n",
    "        np_img = np.array(img)\n",
    "        my_list.append(np_img)\n",
    "my_list = np.array(my_list)\n",
    "print(my_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "# 0 up, 1 down, 2 left, 3 right, 4 zoom in, 5 zoom out, 6 two, 7 three, 8 four, 9 five\n",
    "labels = [0,0,0,0,0,0,0,0,0,0,0,0,\n",
    "         1,1,1,1,1,1,1,1,1,1,1,\n",
    "         2,2,2,2,2,2,2,2,2,2,2,2,\n",
    "         3,3,3,3,3,3,3,3,3,3,3,3,\n",
    "         4,4,4,4,4,4,4,4,4,4,4,4,\n",
    "         5,5,5,5,5,5,5,5,5,5,5,5,\n",
    "         6,6,6,6,6,6,6,6,6,6,6,\n",
    "         7,7,7,7,7,7,7,7,7,7,7,\n",
    "         8,8,8,8,8,8,8,8,8,8,8,8,\n",
    "         9,9,9,9,9,9,9,9,9,9,9,9]\n",
    "print(len(labels))\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.c_[my_list.reshape(len(my_list), -1), labels.reshape(len(labels), -1)]\n",
    "X_orig = c[:, :my_list.size//len(my_list)].reshape(my_list.shape)\n",
    "Y_orig = c[:, my_list.size//len(my_list):].reshape(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "106\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "X_test_orig = X_orig[0:10]\n",
    "Y_test_orig = Y_orig[0:10]\n",
    "X_train_orig = X_orig[11:117]\n",
    "Y_train_orig = Y_orig[11:117]\n",
    "print(len(X_train_orig))\n",
    "print(len(Y_train_orig))\n",
    "print(len(X_test_orig))\n",
    "print(len(Y_test_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig/255\n",
    "X_test = X_test_orig/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = convert_to_one_hot(Y_train_orig, 10).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 106\n",
      "number of test examples = 10\n",
      "X_train shape: (106, 224, 224, 3)\n",
      "Y_train shape: (106, 10)\n",
      "X_test shape: (10, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n",
    "    Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    W1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    parameters = {\"W1\": W1,\"W2\": W2}\n",
    "    return parameters\n",
    "\n",
    "def forward_prop(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    P2 = tf.layers.Flatten()(P2)\n",
    "    Z3 = tf.keras.layers.Dense(10, activation=None)(P2)\n",
    "    return Z3\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3,labels=Y))\n",
    "    #cost = -tf.reduce_sum(Y*tf.log(tf.clip_by_value(Z3,1e-10,1.0)))\n",
    "    cost = -tf.reduce_sum(Y*tf.log(tf.clip_by_value(Z3,1e-10,1.0)))\n",
    "    #labels_sum = tf.reduce_sum(Y, axis=-1)\n",
    "    #print(labels)\n",
    "    #softmax = tf.nn.softmax(Z3)\n",
    "    #cost = tf.reduce_mean(-tf.reduce_sum(softmax * tf.log(Y), axis=-1))\n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009, num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    ops.reset_default_graph()                         \n",
    "    tf.set_random_seed(1)\n",
    "    seed = 3                                          \n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = [] \n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_prop(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                \n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 716.773804\n",
      "Cost after epoch 5: 253.284351\n",
      "Cost after epoch 10: 253.284355\n",
      "Cost after epoch 15: 253.284355\n",
      "Cost after epoch 20: 253.284355\n",
      "Cost after epoch 25: 253.284355\n",
      "Cost after epoch 30: 253.284355\n",
      "Cost after epoch 35: 253.284363\n",
      "Cost after epoch 40: 253.284363\n",
      "Cost after epoch 45: 253.284355\n",
      "Cost after epoch 50: 253.284367\n",
      "Cost after epoch 55: 253.284355\n",
      "Cost after epoch 60: 253.284355\n",
      "Cost after epoch 65: 253.284363\n",
      "Cost after epoch 70: 253.284363\n",
      "Cost after epoch 75: 253.284355\n",
      "Cost after epoch 80: 253.284355\n",
      "Cost after epoch 85: 253.284365\n",
      "Cost after epoch 90: 253.284355\n",
      "Cost after epoch 95: 253.284355\n"
     ]
    }
   ],
   "source": [
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
